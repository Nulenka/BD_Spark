{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c39ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData. Фреймворк Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Урок 4. Машинное обучение на pySpark на примере линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea88a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Работа на уроке: https://colab.research.google.com/drive/18kCmFr3QdlooCC0TUm9teaukbIX26MLY?usp=sharing\n",
    "Joblib: https://colab.research.google.com/drive/1esnt7oWobjet5Yj1rbFKBLUyA1uG5QTa?usp=sharing\n",
    "Estimators: https://colab.research.google.com/drive/14XmbKrZOx5IOI5OXY26VeGjzAkMJAiut?usp=sharing\n",
    "Transformers: https://colab.research.google.com/drive/1dKsDj1Kc7acFz8YC9_I-4utYJdU_4D9P?usp=sharing\n",
    "HW - перепишите всё на spark (без pandas и sklaarn), код моментами немного не очевидный (чтобы сложнее было переписать 1к1), \n",
    "но на самом деле простой: https://colab.research.google.com/drive/1_JScmu1V43DJ44Q2zwabWd2FDp0TVFTF#scrollTo=zDyEK4QgMH3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"C2hfVwCGAwt9\",\n",
    "    \"outputId\": \"7c969092-fcac-4643-b08d-d58a32a571d7\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n",
    "      \"Collecting pyspark\\n\",\n",
    "      \"  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\\n\",\n",
    "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m281.4/281.4 MB\\u001b[0m \\u001b[31m4.7 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
    "      \"\\u001b[?25h  Preparing metadata (setup.py) ... \\u001b[?25l\\u001b[?25hdone\\n\",\n",
    "      \"Collecting py4j==0.10.9.5\\n\",\n",
    "      \"  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\\n\",\n",
    "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m199.7/199.7 KB\\u001b[0m \\u001b[31m24.2 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
    "      \"\\u001b[?25hBuilding wheels for collected packages: pyspark\\n\",\n",
    "      \"  Building wheel for pyspark (setup.py) ... \\u001b[?25l\\u001b[?25hdone\\n\",\n",
    "      \"  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=0e74b9dc220ed2b5cb29a64b980d99be1a9117d1ea56bafab524535bb5c26958\\n\",\n",
    "      \"  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\\n\",\n",
    "      \"Successfully built pyspark\\n\",\n",
    "      \"Installing collected packages: py4j, pyspark\\n\",\n",
    "      \"Successfully installed py4j-0.10.9.5 pyspark-3.3.1\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"pip install pyspark\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"E3Q9g_UyNxS6\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from pyspark.sql import SparkSession\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"spark = SparkSession.builder\\\\\\n\",\n",
    "    \"    .master(\\\"local[2]\\\")\\\\\\n\",\n",
    "    \"    .appName(\\\"Lesson_5\\\")\\\\\\n\",\n",
    "    \"    .config(\\\"spark.executor.instances\\\",2)\\\\\\n\",\n",
    "    \"    .config(\\\"spark.executor.memory\\\",'2g')\\\\\\n\",\n",
    "    \"    .config(\\\"spark.executor.cores\\\",1)\\\\\\n\",\n",
    "    \"    .getOrCreate()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"sc = spark.sparkContext\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"dnXLtjUr_FkX\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# Оконные функции\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"JGioDDCQ_V_-\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"Оконная функция - функция, которая работает с выделенным набором строк (окном, партицией) и выполняет вычисление для этого набора строк в отдельном столбце. \\n\",\n",
    "    \"\\n\",\n",
    "    \"Партиции (окна из набора строк) - это набор строк, указанный для оконной функции по одному из столбцов или группе столбцов таблицы. Партиции для каждой оконной функции в запросе могут быть разделены по различным колонкам таблицы.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"b6tdUDN5_Ee0\",\n",
    "    \"outputId\": \"656fe78c-bc07-4aef-cec3-de9a6b6e4625\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"root\\n\",\n",
    "      \" |-- Product: string (nullable = true)\\n\",\n",
    "      \" |-- Amount: long (nullable = true)\\n\",\n",
    "      \" |-- Country: string (nullable = true)\\n\",\n",
    "      \"\\n\",\n",
    "      \"+-------+------+-------+\\n\",\n",
    "      \"|Product|Amount|Country|\\n\",\n",
    "      \"+-------+------+-------+\\n\",\n",
    "      \"|Banana |1000  |USA    |\\n\",\n",
    "      \"|Carrots|1500  |USA    |\\n\",\n",
    "      \"|Beans  |1600  |USA    |\\n\",\n",
    "      \"|Orange |2000  |USA    |\\n\",\n",
    "      \"|Orange |2000  |USA    |\\n\",\n",
    "      \"|Banana |400   |China  |\\n\",\n",
    "      \"|Carrots|1200  |China  |\\n\",\n",
    "      \"|Beans  |1500  |China  |\\n\",\n",
    "      \"|Orange |4000  |China  |\\n\",\n",
    "      \"|Banana |2000  |Canada |\\n\",\n",
    "      \"|Carrots|2000  |Canada |\\n\",\n",
    "      \"|Beans  |2000  |Mexico |\\n\",\n",
    "      \"+-------+------+-------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Предположим, что есть таблицы:\\n\",\n",
    "    \"from pyspark.sql import functions as F\\n\",\n",
    "    \"from pyspark.sql.types import *\\n\",\n",
    "    \"\\n\",\n",
    "    \"data =[\\n\",\n",
    "    \"    (\\\"Banana\\\",1000,\\\"USA\\\"), (\\\"Carrots\\\",1500,\\\"USA\\\"), (\\\"Beans\\\",1600,\\\"USA\\\"),\\\\\\n\",\n",
    "    \"    (\\\"Orange\\\",2000,\\\"USA\\\"), (\\\"Orange\\\",2000,\\\"USA\\\"), (\\\"Banana\\\",400,\\\"China\\\"),\\\\\\n\",\n",
    "    \"    (\\\"Carrots\\\",1200,\\\"China\\\"), (\\\"Beans\\\",1500,\\\"China\\\"), (\\\"Orange\\\",4000,\\\"China\\\"),\\\\\\n\",\n",
    "    \"    (\\\"Banana\\\",2000,\\\"Canada\\\"), (\\\"Carrots\\\",2000,\\\"Canada\\\"), (\\\"Beans\\\",2000,\\\"Mexico\\\")\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"columns = [\\\"Product\\\",\\\"Amount\\\", \\\"Country\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = spark.createDataFrame(data=data, schema=columns)\\n\",\n",
    "    \"df.printSchema()\\n\",\n",
    "    \"df.show(truncate=False)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"jhq8wrA8BNia\",\n",
    "    \"outputId\": \"371a5ec3-32c2-46a6-ffef-e8f616f28d13\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/usr/local/lib/python3.8/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\\n\",\n",
    "      \"  warnings.warn(\\\"Deprecated in 2.0, use createOrReplaceTempView instead.\\\", FutureWarning)\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-------+------+-------+---+\\n\",\n",
    "      \"|Product|Amount|Country| rn|\\n\",\n",
    "      \"+-------+------+-------+---+\\n\",\n",
    "      \"| Banana|  2000| Canada|  1|\\n\",\n",
    "      \"|Carrots|  2000| Canada|  2|\\n\",\n",
    "      \"| Banana|   400|  China|  1|\\n\",\n",
    "      \"|Carrots|  1200|  China|  2|\\n\",\n",
    "      \"|  Beans|  1500|  China|  3|\\n\",\n",
    "      \"| Orange|  4000|  China|  4|\\n\",\n",
    "      \"|  Beans|  2000| Mexico|  1|\\n\",\n",
    "      \"| Banana|  1000|    USA|  1|\\n\",\n",
    "      \"|Carrots|  1500|    USA|  2|\\n\",\n",
    "      \"|  Beans|  1600|    USA|  3|\\n\",\n",
    "      \"| Orange|  2000|    USA|  4|\\n\",\n",
    "      \"| Orange|  2000|    USA|  5|\\n\",\n",
    "      \"+-------+------+-------+---+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# в sql оконная функция записывается следующим образом\\n\",\n",
    "    \"df.registerTempTable('df')\\n\",\n",
    "    \"\\n\",\n",
    "    \"spark.sql('''\\n\",\n",
    "    \"select *, \\n\",\n",
    "    \"row_number() over( partition by Country order by Amount ) as rn from df\\n\",\n",
    "    \"''').show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"9grWEK6CBbBK\",\n",
    "    \"outputId\": \"0afaf53c-8766-40a0-d9b2-1a16b62a2b4c\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-------+------+-------+---+\\n\",\n",
    "      \"|Product|Amount|Country| rn|\\n\",\n",
    "      \"+-------+------+-------+---+\\n\",\n",
    "      \"| Banana|  2000| Canada|  1|\\n\",\n",
    "      \"|Carrots|  2000| Canada|  2|\\n\",\n",
    "      \"| Banana|   400|  China|  1|\\n\",\n",
    "      \"|Carrots|  1200|  China|  2|\\n\",\n",
    "      \"|  Beans|  1500|  China|  3|\\n\",\n",
    "      \"| Orange|  4000|  China|  4|\\n\",\n",
    "      \"|  Beans|  2000| Mexico|  1|\\n\",\n",
    "      \"| Banana|  1000|    USA|  1|\\n\",\n",
    "      \"|Carrots|  1500|    USA|  2|\\n\",\n",
    "      \"|  Beans|  1600|    USA|  3|\\n\",\n",
    "      \"| Orange|  2000|    USA|  4|\\n\",\n",
    "      \"| Orange|  2000|    USA|  5|\\n\",\n",
    "      \"+-------+------+-------+---+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# в спарке следующим образом\\n\",\n",
    "    \"from pyspark.sql import Window\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"windSpec = Window()\\\\\\n\",\n",
    "    \"    .partitionBy('Country')\\\\\\n\",\n",
    "    \"    .orderBy('Amount')\\n\",\n",
    "    \"    # .rowsBetween(Window.unboundedPreceding, Window.currentRow - 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df.withColumn('rn', F.row_number().over(windSpec)).show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"dVGNGR7pN1KC\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# Самостоятельная работа к уроку\\n\",\n",
    "    \"На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"agigNChqOHnK\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\\n\",\n",
    "    \"\\n\",\n",
    "    \" Каждая строчка это продажа жилья, которая состоит из следующих полей (думаю описание не требуется):\\n\",\n",
    "    \"*   date of sale\\n\",\n",
    "    \"*   price\\n\",\n",
    "    \"*   property type\\n\",\n",
    "    \"*   number of bedrooms\\n\",\n",
    "    \"*   4digit postcode\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"i-36e65zdEEh\",\n",
    "    \"outputId\": \"248f9bd4-6556-41f3-8ad1-b0fb03a6ebd9\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"--2023-01-23 12:12:59--  https://drive.google.com/uc?export=download&id=1xbtFBPz50OBoyYFVGd-B03pCTJdCax07\\n\",\n",
    "      \"Resolving drive.google.com (drive.google.com)... 173.194.217.100, 173.194.217.139, 173.194.217.113, ...\\n\",\n",
    "      \"Connecting to drive.google.com (drive.google.com)|173.194.217.100|:443... connected.\\n\",\n",
    "      \"HTTP request sent, awaiting response... 303 See Other\\n\",\n",
    "      \"Location: https://doc-0c-5k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/98tto341fq2o32hfickf06864c3c2rmh/1674475950000/04099736791713398091/*/1xbtFBPz50OBoyYFVGd-B03pCTJdCax07?e=download&uuid=fc78e771-fe5b-4a7f-b34d-0919fb974561 [following]\\n\",\n",
    "      \"Warning: wildcards not supported in HTTP.\\n\",\n",
    "      \"--2023-01-23 12:12:59--  https://doc-0c-5k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/98tto341fq2o32hfickf06864c3c2rmh/1674475950000/04099736791713398091/*/1xbtFBPz50OBoyYFVGd-B03pCTJdCax07?e=download&uuid=fc78e771-fe5b-4a7f-b34d-0919fb974561\\n\",\n",
    "      \"Resolving doc-0c-5k-docs.googleusercontent.com (doc-0c-5k-docs.googleusercontent.com)... 142.251.162.132, 2607:f8b0:400c:c0b::84\\n\",\n",
    "      \"Connecting to doc-0c-5k-docs.googleusercontent.com (doc-0c-5k-docs.googleusercontent.com)|142.251.162.132|:443... connected.\\n\",\n",
    "      \"HTTP request sent, awaiting response... 200 OK\\n\",\n",
    "      \"Length: 1505497 (1.4M) [text/csv]\\n\",\n",
    "      \"Saving to: ‘raw_sales.csv’\\n\",\n",
    "      \"\\n\",\n",
    "      \"raw_sales.csv       100%[===================>]   1.44M  --.-KB/s    in 0.01s   \\n\",\n",
    "      \"\\n\",\n",
    "      \"2023-01-23 12:12:59 (129 MB/s) - ‘raw_sales.csv’ saved [1505497/1505497]\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"!wget 'https://drive.google.com/uc?export=download&id=1xbtFBPz50OBoyYFVGd-B03pCTJdCax07' -O raw_sales.csv\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"WpWic7isdH6R\",\n",
    "    \"outputId\": \"85e48fc7-9156-4950-bb37-713382be1929\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"root\\n\",\n",
    "      \" |-- datesold: timestamp (nullable = true)\\n\",\n",
    "      \" |-- postcode: integer (nullable = true)\\n\",\n",
    "      \" |-- price: integer (nullable = true)\\n\",\n",
    "      \" |-- propertyType: string (nullable = true)\\n\",\n",
    "      \" |-- bedrooms: integer (nullable = true)\\n\",\n",
    "      \"\\n\",\n",
    "      \"+-------------------+--------+-------+------------+--------+\\n\",\n",
    "      \"|datesold           |postcode|price  |propertyType|bedrooms|\\n\",\n",
    "      \"+-------------------+--------+-------+------------+--------+\\n\",\n",
    "      \"|2007-02-07 00:00:00|2607    |525000 |house       |4       |\\n\",\n",
    "      \"|2007-02-27 00:00:00|2906    |290000 |house       |3       |\\n\",\n",
    "      \"|2007-03-07 00:00:00|2905    |328000 |house       |3       |\\n\",\n",
    "      \"|2007-03-09 00:00:00|2905    |380000 |house       |4       |\\n\",\n",
    "      \"|2007-03-21 00:00:00|2906    |310000 |house       |3       |\\n\",\n",
    "      \"|2007-04-04 00:00:00|2905    |465000 |house       |4       |\\n\",\n",
    "      \"|2007-04-24 00:00:00|2607    |399000 |house       |3       |\\n\",\n",
    "      \"|2007-04-30 00:00:00|2606    |1530000|house       |4       |\\n\",\n",
    "      \"|2007-05-24 00:00:00|2902    |359000 |house       |3       |\\n\",\n",
    "      \"|2007-05-25 00:00:00|2906    |320000 |house       |3       |\\n\",\n",
    "      \"|2007-06-26 00:00:00|2902    |385000 |house       |3       |\\n\",\n",
    "      \"|2007-06-27 00:00:00|2906    |305000 |house       |3       |\\n\",\n",
    "      \"|2007-06-27 00:00:00|2612    |850000 |house       |4       |\\n\",\n",
    "      \"|2007-06-28 00:00:00|2904    |765000 |house       |4       |\\n\",\n",
    "      \"|2007-06-30 00:00:00|2615    |517000 |house       |4       |\\n\",\n",
    "      \"|2007-07-02 00:00:00|2914    |800000 |house       |5       |\\n\",\n",
    "      \"|2007-07-03 00:00:00|2906    |336000 |house       |3       |\\n\",\n",
    "      \"|2007-07-06 00:00:00|2615    |535000 |house       |5       |\\n\",\n",
    "      \"|2007-07-07 00:00:00|2602    |900000 |house       |4       |\\n\",\n",
    "      \"|2007-07-08 00:00:00|2600    |327000 |house       |1       |\\n\",\n",
    "      \"+-------------------+--------+-------+------------+--------+\\n\",\n",
    "      \"only showing top 20 rows\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = spark.read.csv('raw_sales.csv', header=True, inferSchema=True)\\n\",\n",
    "    \"df.printSchema()\\n\",\n",
    "    \"df.show(truncate=False)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"xisyFowtQgx-\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"## Задание 1\\n\",\n",
    "    \"Добавьте к таблице следующие поля:\\n\",\n",
    "    \"*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode)\\n\",\n",
    "    \"*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\\n\",\n",
    "    \"*  Стоимость последнего проданного дома до текущего\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"7fGJJreDczDK\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from pyspark.sql import Window\\n\",\n",
    "    \"import pyspark.sql.functions as F\\n\",\n",
    "    \"from pyspark.sql.functions import col, asc,desc\\n\",\n",
    "    \"\\n\",\n",
    "    \"windSpec_before = Window()\\\\\\n\",\n",
    "    \"    .partitionBy('postcode')\\\\\\n\",\n",
    "    \"    .orderBy('datesold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = df.withColumn('average_price_before', F.avg('price').over(windSpec_before))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"QOT40OOb5TZ6\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"windSpec_after = Window()\\\\\\n\",\n",
    "    \"    .partitionBy('postcode')\\\\\\n\",\n",
    "    \"    .orderBy(col('datesold').desc())\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = df.withColumn('average_price_after', F.avg('price').over(windSpec_after))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"oK9MgruF_jsO\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df = df.withColumn('previous_sold_price', F.lag('price', 1).over(windSpec_before))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"-goBnh4NF-cJ\",\n",
    "    \"outputId\": \"7e20c2f4-b296-45d0-b926-8e37872b82cf\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-------------------+--------+-------+------------+--------+--------------------+-------------------+-------------------+\\n\",\n",
    "      \"|           datesold|postcode|  price|propertyType|bedrooms|average_price_before|average_price_after|previous_sold_price|\\n\",\n",
    "      \"+-------------------+--------+-------+------------+--------+--------------------+-------------------+-------------------+\\n\",\n",
    "      \"|2007-07-08 00:00:00|    2600| 327000|       house|       1|            327000.0| 1028204.3785488959|               null|\\n\",\n",
    "      \"|2007-08-16 00:00:00|    2600| 790000|       house|       4|            558500.0| 1029312.1263823065|             327000|\\n\",\n",
    "      \"|2007-12-05 00:00:00|    2600| 825000|       house|       3|   647333.3333333334| 1029690.7848101265|             790000|\\n\",\n",
    "      \"|2008-01-21 00:00:00|    2600| 315000|        unit|       1|            564250.0|  1030015.175911252|             825000|\\n\",\n",
    "      \"|2008-04-24 00:00:00|    2600| 292500|       house|       1|            509900.0| 1031150.1206349207|             315000|\\n\",\n",
    "      \"|2008-05-30 00:00:00|    2600| 329000|        unit|       2|            479750.0| 1032324.4451510333|             292500|\\n\",\n",
    "      \"|2008-06-19 00:00:00|    2600| 765000|       house|       5|            520500.0| 1033444.3885350318|             329000|\\n\",\n",
    "      \"|2008-07-29 00:00:00|    2600| 927000|       house|       4|            571312.5| 1033872.5295055822|             765000|\\n\",\n",
    "      \"|2008-09-02 00:00:00|    2600|1380000|       house|       5|   661166.6666666666| 1034043.2523961661|             927000|\\n\",\n",
    "      \"|2008-09-08 00:00:00|    2600| 740000|       house|       3|            669050.0|       1033489.7216|            1380000|\\n\",\n",
    "      \"+-------------------+--------+-------+------------+--------+--------------------+-------------------+-------------------+\\n\",\n",
    "      \"only showing top 10 rows\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df.show(10)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"Qvh2x6_8YU3F\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"## Задание 2\\n\",\n",
    "    \"В итоге у вас таблица с колонками (или нечто похожее):\\n\",\n",
    "    \"*   price\\n\",\n",
    "    \"*   Среднегодовая цена\\n\",\n",
    "    \"*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\\n\",\n",
    "    \"*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\\n\",\n",
    "    \"*  Стоимость последнего проданного дома до текущего ((1 балл)\\n\",\n",
    "    \"*  и др.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Посчитайте кол-во уникальных значений в каждой строчке (unique(row)) (ипользуйте udf). Попробуйте сделать то же самое используя pandas udf.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"2eV6P_dNgXhI\",\n",
    "    \"outputId\": \"6caf7901-9435-4043-9d48-e793ffd6d6df\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-------------------------------+\\n\",\n",
    "      \"|approx_count_distinct(postcode)|\\n\",\n",
    "      \"+-------------------------------+\\n\",\n",
    "      \"|                             27|\\n\",\n",
    "      \"+-------------------------------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df.select(F.approx_count_distinct('postcode')).show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"LEl8YHuvEVil\",\n",
    "    \"outputId\": \"426bdff8-7fe1-4657-fc2a-8e006d64036d\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-----------------------------------+\\n\",\n",
    "      \"|approx_count_distinct(propertyType)|\\n\",\n",
    "      \"+-----------------------------------+\\n\",\n",
    "      \"|                                  2|\\n\",\n",
    "      \"+-----------------------------------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df.select(F.approx_count_distinct('propertyType')).show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"NbvISPGoEYyu\",\n",
    "    \"outputId\": \"a53552d4-2703-4b15-e02f-1e419eb8a59f\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-------------------------------+\\n\",\n",
    "      \"|approx_count_distinct(bedrooms)|\\n\",\n",
    "      \"+-------------------------------+\\n\",\n",
    "      \"|                              6|\\n\",\n",
    "      \"+-------------------------------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df.select(F.approx_count_distinct('bedrooms')).show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"pmSZTI9PAwQb\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# Задание 3\\n\",\n",
    "    \"SQL like case when или if elif else\\n\",\n",
    "    \"\\n\",\n",
    "    \"Создайте колонку, в которой в которой будет отображаться \\\"+\\\", \\\"-\\\" или \\\"=\\\", если \\\"Средняя стомость 10 проданных домов до текущего в том же районе\\\" больше, меньше или равно \\\"Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\\\", соотвественно.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Если одно из полей Null, запишите в эту колонку \\\"Нет данных\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"-rfOBthog-2Q\",\n",
    "    \"outputId\": \"4e211620-a586-4a02-e20b-be00afbc2209\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-------------------+--------+-------+------------+--------+--------------------+-------------------+-------------------+------+\\n\",\n",
    "      \"|           datesold|postcode|  price|propertyType|bedrooms|average_price_before|average_price_after|previous_sold_price|ifelse|\\n\",\n",
    "      \"+-------------------+--------+-------+------------+--------+--------------------+-------------------+-------------------+------+\\n\",\n",
    "      \"|2007-07-08 00:00:00|    2600| 327000|       house|       1|            327000.0| 1028204.3785488959|               null|     -|\\n\",\n",
    "      \"|2007-08-16 00:00:00|    2600| 790000|       house|       4|            558500.0| 1029312.1263823065|             327000|     -|\\n\",\n",
    "      \"|2007-12-05 00:00:00|    2600| 825000|       house|       3|   647333.3333333334| 1029690.7848101265|             790000|     -|\\n\",\n",
    "      \"|2008-01-21 00:00:00|    2600| 315000|        unit|       1|            564250.0|  1030015.175911252|             825000|     -|\\n\",\n",
    "      \"|2008-04-24 00:00:00|    2600| 292500|       house|       1|            509900.0| 1031150.1206349207|             315000|     -|\\n\",\n",
    "      \"|2008-05-30 00:00:00|    2600| 329000|        unit|       2|            479750.0| 1032324.4451510333|             292500|     -|\\n\",\n",
    "      \"|2008-06-19 00:00:00|    2600| 765000|       house|       5|            520500.0| 1033444.3885350318|             329000|     -|\\n\",\n",
    "      \"|2008-07-29 00:00:00|    2600| 927000|       house|       4|            571312.5| 1033872.5295055822|             765000|     -|\\n\",\n",
    "      \"|2008-09-02 00:00:00|    2600|1380000|       house|       5|   661166.6666666666| 1034043.2523961661|             927000|     -|\\n\",\n",
    "      \"|2008-09-08 00:00:00|    2600| 740000|       house|       3|            669050.0|       1033489.7216|            1380000|     -|\\n\",\n",
    "      \"+-------------------+--------+-------+------------+--------+--------------------+-------------------+-------------------+------+\\n\",\n",
    "      \"only showing top 10 rows\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df.withColumn('ifelse', F.when(F.col('postcode').isNull() | F.col('price').isNull(), F.lit('Нет данных')).when(F.col('average_price_before') > F.col('average_price_after'), F.lit('+')).when(F.col('average_price_before') < F.col('average_price_after'), '-').otherwise('=')).show(10)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"k2q7HSEqWBVn\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# Задание 4\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"c3pfUThFQtE6\",\n",
    "    \"outputId\": \"42111b69-1497-4200-c91d-f571f9a31143\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"df1\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|key_1|value_1|value_2|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|  abc|     10|     20|\\n\",\n",
    "      \"|  def|    100|    300|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"\\n\",\n",
    "      \"df2\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|key_2|value_1|value_2|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|  abc|    5.5|    2.2|\\n\",\n",
    "      \"|  xyz|   10.1|   13.5|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Создаём датасет для примеров\\n\",\n",
    "    \"dataset_1 = [\\n\",\n",
    "    \"  {\\n\",\n",
    "    \"    'key_1' : 'abc',\\n\",\n",
    "    \"    'value_1' : 10,\\n\",\n",
    "    \"    'value_2' : 20\\n\",\n",
    "    \"  },\\n\",\n",
    "    \"  {\\n\",\n",
    "    \"    'key_1' : 'def',\\n\",\n",
    "    \"    'value_1' : 100,\\n\",\n",
    "    \"    'value_2' : 300\\n\",\n",
    "    \"  }\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataset_2 = [\\n\",\n",
    "    \"  {\\n\",\n",
    "    \"    'key_2' : 'abc',\\n\",\n",
    "    \"    'value_1' : 5.5,\\n\",\n",
    "    \"    'value_2' : 2.2\\n\",\n",
    "    \"  },\\n\",\n",
    "    \"  {\\n\",\n",
    "    \"    'key_2' : 'xyz',\\n\",\n",
    "    \"    'value_1' : 10.1,\\n\",\n",
    "    \"    'value_2' : 13.5\\n\",\n",
    "    \"  }\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"df1 = spark.createDataFrame(dataset_1)\\n\",\n",
    "    \"print('df1')\\n\",\n",
    "    \"df1.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"df2 = spark.createDataFrame(dataset_2)\\n\",\n",
    "    \"print('df2')\\n\",\n",
    "    \"df2.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"o0E_1iKeWFeY\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"## Задание 4.1\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"od3V0xa4V7U8\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Создайте джойн, чтобы получить следующую таблицу\\n\",\n",
    "    \"# +---+-------+-------+\\n\",\n",
    "    \"# |key|value_1|value_2|\\n\",\n",
    "    \"# +---+-------+-------+\\n\",\n",
    "    \"# |abc|     10|     20|\\n\",\n",
    "    \"# +---+-------+-------+\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"BRDcZgNKjZru\",\n",
    "    \"outputId\": \"460df843-9465-48a0-81a4-129e7527c508\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|key_1|value_1|value_2|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|  abc|     10|     20|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df1.join(df2, on=df1.key_1 == df2.key_2, how='semi').show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"qrwYa2ZAWYmF\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"## Задание 4.2\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"xEb-gGG8WQST\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Создайте джойн, чтобы получить следующую таблицу\\n\",\n",
    "    \"# +---+-------+-------+\\n\",\n",
    "    \"# |key|value_1|value_2|\\n\",\n",
    "    \"# +---+-------+-------+\\n\",\n",
    "    \"# |def|    100|    300|\\n\",\n",
    "    \"# +---+-------+-------+\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"IKM1D_FIjBc9\",\n",
    "    \"outputId\": \"05ee1dfe-4182-4017-d28e-9a9b14ed0352\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|key_1|value_1|value_2|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"|  def|    100|    300|\\n\",\n",
    "      \"+-----+-------+-------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df1.join(df2, on=df1.key_1 == df2.key_2, how='anti').show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"id\": \"GbzsGu30WZTb\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"## Задание 4.3\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"XJ84QTURWWY_\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Создайте Inner джойн с условиями ---hidden---, для df1 и df2, соответсвенно\\n\",\n",
    "    \"# В  итоге получится таблица\\n\",\n",
    "    \"# +---+-------+-------+---+-------+-------+\\n\",\n",
    "    \"# |key|value_1|value_2|key|value_1|value_2|\\n\",\n",
    "    \"# +---+-------+-------+---+-------+-------+\\n\",\n",
    "    \"# |abc|     10|     20|abc|    5.5|    2.2|\\n\",\n",
    "    \"# |abc|     10|     20|xyz|   10.1|   13.5|\\n\",\n",
    "    \"# |def|    100|    300|abc|    5.5|    2.2|\\n\",\n",
    "    \"# |def|    100|    300|xyz|   10.1|   13.5|\\n\",\n",
    "    \"# +---+-------+-------+---+-------+-------+\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"colab\": {\n",
    "     \"base_uri\": \"https://localhost:8080/\"\n",
    "    },\n",
    "    \"id\": \"2zzGUJN7inrF\",\n",
    "    \"outputId\": \"f86f4459-06a1-4ef4-bfd4-9d5cab618763\"\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"+-----+-------+-------+-----+-------+-------+\\n\",\n",
    "      \"|key_1|value_1|value_2|key_2|value_1|value_2|\\n\",\n",
    "      \"+-----+-------+-------+-----+-------+-------+\\n\",\n",
    "      \"|  abc|     10|     20|  abc|    5.5|    2.2|\\n\",\n",
    "      \"|  abc|     10|     20|  xyz|   10.1|   13.5|\\n\",\n",
    "      \"|  def|    100|    300|  abc|    5.5|    2.2|\\n\",\n",
    "      \"|  def|    100|    300|  xyz|   10.1|   13.5|\\n\",\n",
    "      \"+-----+-------+-------+-----+-------+-------+\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df1.join(df2, on=df1.value_2 > df2.value_2, how='inner').show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"PNwKGLKri4xr\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"colab\": {\n",
    "   \"provenance\": []\n",
    "  },\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.15\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502032a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0,\n",
    "  \"metadata\": {\n",
    "    \"colab\": {\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"name\": \"python3\",\n",
    "      \"display_name\": \"Python 3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\"\n",
    "    }\n",
    "  },\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"!pip install pyspark\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"AszXfjLrTDqJ\",\n",
    "        \"outputId\": \"c72f1f00-663d-41fe-984f-dc904ab9c2a0\"\n",
    "      },\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n",
    "            \"Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\\n\",\n",
    "            \"Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"E3Q9g_UyNxS6\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"from pyspark.sql import SparkSession\\n\",\n",
    "        \"spark = SparkSession.builder\\\\\\n\",\n",
    "        \"    .master(\\\"local[2]\\\")\\\\\\n\",\n",
    "        \"    .appName(\\\"Lesson_4\\\")\\\\\\n\",\n",
    "        \"    .config(\\\"spark.executor.instances\\\",2)\\\\\\n\",\n",
    "        \"    .config(\\\"spark.executor.memory\\\",'2g')\\\\\\n\",\n",
    "        \"    .config(\\\"spark.executor.cores\\\",1)\\\\\\n\",\n",
    "        \"    .getOrCreate()\\n\",\n",
    "        \"sc = spark.sparkContext\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"dVGNGR7pN1KC\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Самостоятельная работа к уроку 4\\n\",\n",
    "        \"На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"agigNChqOHnK\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\\n\",\n",
    "        \"\\n\",\n",
    "        \" Каждая строчка это продажа жилья, которая состоит из следующих полей:\\n\",\n",
    "        \"*   ```date of sale``` - дата продажи\\n\",\n",
    "        \"*   ```price``` - цена\\n\",\n",
    "        \"*   ```property type``` - тип недвижимости\\n\",\n",
    "        \"*   ```number of bedrooms``` - количество спален\\n\",\n",
    "        \"*   ```4digit postcode``` - 4-хзначный почтовый индекс\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"from pyspark.sql import Window\\n\",\n",
    "        \"from pyspark.sql import functions as F \\n\",\n",
    "        \"from pyspark.sql.pandas.functions import pandas_udf, PandasUDFType\\n\",\n",
    "        \"from pyspark.sql.types import IntegerType\\n\",\n",
    "        \"\\n\",\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"import requests\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"bhJ6KWN-Sh5q\"\n",
    "      },\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"# скачаем файл\\n\",\n",
    "        \"\\n\",\n",
    "        \"train_response = requests.get('https://drive.google.com/uc?id=1uF1CStEeuFUMiXgQ2mhn42Cs9Ax8IUm3')\\n\",\n",
    "        \"with open('raw_sales.csv', 'wb') as file:\\n\",\n",
    "        \"    file.write(train_response.content)\\n\",\n",
    "        \"data = spark.read.csv('raw_sales.csv', header=True, inferSchema=True)\\n\",\n",
    "        \"data.show(5)\\n\",\n",
    "        \"data.printSchema()\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"Jt3sCQTmSh76\",\n",
    "        \"outputId\": \"0b380e6d-ba18-41db-b543-3462817680ac\"\n",
    "      },\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"+-------------------+--------+------+------------+--------+\\n\",\n",
    "            \"|           datesold|postcode| price|propertyType|bedrooms|\\n\",\n",
    "            \"+-------------------+--------+------+------------+--------+\\n\",\n",
    "            \"|2007-02-07 00:00:00|    2607|525000|       house|       4|\\n\",\n",
    "            \"|2007-02-27 00:00:00|    2906|290000|       house|       3|\\n\",\n",
    "            \"|2007-03-07 00:00:00|    2905|328000|       house|       3|\\n\",\n",
    "            \"|2007-03-09 00:00:00|    2905|380000|       house|       4|\\n\",\n",
    "            \"|2007-03-21 00:00:00|    2906|310000|       house|       3|\\n\",\n",
    "            \"+-------------------+--------+------+------------+--------+\\n\",\n",
    "            \"only showing top 5 rows\\n\",\n",
    "            \"\\n\",\n",
    "            \"root\\n\",\n",
    "            \" |-- datesold: timestamp (nullable = true)\\n\",\n",
    "            \" |-- postcode: integer (nullable = true)\\n\",\n",
    "            \" |-- price: integer (nullable = true)\\n\",\n",
    "            \" |-- propertyType: string (nullable = true)\\n\",\n",
    "            \" |-- bedrooms: integer (nullable = true)\\n\",\n",
    "            \"\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"xisyFowtQgx-\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Задание 1\\n\",\n",
    "        \"Добавьте к таблице следующие поля:\\n\",\n",
    "        \"*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode)\\n\",\n",
    "        \"*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\\n\",\n",
    "        \"*  Стоимость последнего проданного дома до текущего\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"# группируем данные по postcode и сортируем в порядке возрастания даты продажи\\n\",\n",
    "        \"window = Window.partitionBy('postcode').orderBy('datesold')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# avg_price_before_sale - получим среднюю стоимость домов до текущей продажи\\n\",\n",
    "        \"# диапазон задан с помощью window.rowsBetween(Window.currentRow-10, Window.currentRow-1)\\n\",\n",
    "        \"# среднее найдено с помощью avg()\\n\",\n",
    "        \"df = (\\n\",\n",
    "        \"    data.withColumn('avg_price_before_sale', F.avg(F.col('price'))\\n\",\n",
    "        \"    .over(window.rowsBetween(Window.currentRow-10, Window.currentRow-1)))\\n\",\n",
    "        \")\\n\",\n",
    "        \"# avg_price_after_sale - аналогично - средняя стоимость домов после текущей продажи\\n\",\n",
    "        \"df = (\\n\",\n",
    "        \"    df.withColumn('avg_price_after_sale', F.avg(F.col('price'))\\n\",\n",
    "        \"    .over(window.rowsBetween(Window.currentRow+1, Window.currentRow+10)))\\n\",\n",
    "        \")\\n\",\n",
    "        \"# last_price_before_sale - получим стоимость последнего проданного дома до текущего\\n\",\n",
    "        \"# предыдущее значение в рамках окна получено с помощью lag(колонка, на_сколько_назад)\\n\",\n",
    "        \"# рамки окна определены с помощью over(window)\\n\",\n",
    "        \"df = df.withColumn('last_price_before_sale', F.lag(F.col('price'), 1).over(window))\\n\",\n",
    "        \"\\n\",\n",
    "        \"# фильтруем данные, чтобы оставить только проданные дома\\n\",\n",
    "        \"df = df.filter(F.col('propertyType') == 'house')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# сделаем новые столбцы типом int (это пригодится позже для поиска уникальных значений в строке)\\n\",\n",
    "        \"df = df.selectExpr('datesold', 'postcode', 'price', 'propertyType', 'bedrooms',\\n\",\n",
    "        \"                   'cast(avg_price_before_sale as int) as avg_price_before_sale', \\n\",\n",
    "        \"                   'cast(avg_price_after_sale as int) as avg_price_after_sale',\\n\",\n",
    "        \"                   'last_price_before_sale')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# и вот он результат\\n\",\n",
    "        \"#df.select('*').orderBy('postcode', 'datesold').show(10)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# в итоговом выводе  с помощью filter() уберём строки с null\\n\",\n",
    "        \"(\\n\",\n",
    "        \"    df.filter(F.col('avg_price_before_sale').isNotNull())\\n\",\n",
    "        \"    .select('*').orderBy('postcode', 'datesold').show(10)\\n\",\n",
    "        \")\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"y69PpxepIJDe\",\n",
    "        \"outputId\": \"1adb7b5d-9b88-4d2d-d753-72226e267133\"\n",
    "      },\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\\n\",\n",
    "            \"|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\\n\",\n",
    "            \"|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|\\n\",\n",
    "            \"|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|\\n\",\n",
    "            \"|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|\\n\",\n",
    "            \"|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|\\n\",\n",
    "            \"|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|\\n\",\n",
    "            \"|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|\\n\",\n",
    "            \"|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|\\n\",\n",
    "            \"|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|\\n\",\n",
    "            \"|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|\\n\",\n",
    "            \"|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\\n\",\n",
    "            \"only showing top 10 rows\\n\",\n",
    "            \"\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Qvh2x6_8YU3F\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Задание 2\\n\",\n",
    "        \"В итоге у вас таблица с колонками (или нечто похожее):\\n\",\n",
    "        \"*   price\\n\",\n",
    "        \"*   Среднегодовая цена\\n\",\n",
    "        \"*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\\n\",\n",
    "        \"*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\\n\",\n",
    "        \"*  Стоимость последнего проданного дома до текущего ((1 балл)\\n\",\n",
    "        \"*  и др.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Посчитайте кол-во уникальных значений в каждой строчке (unique(row)) (ипользуйте udf). Попробуйте сделать то же самое используя pandas udf.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"# udf - в функцию с помощью array(*df) приходит список\\n\",\n",
    "        \"@F.udf(returnType=IntegerType())\\n\",\n",
    "        \"def count_unique_udf(row):\\n\",\n",
    "        \"    return len(set(row))\\n\",\n",
    "        \"(\\n\",\n",
    "        \"    df.filter(F.col('avg_price_before_sale').isNotNull())\\n\",\n",
    "        \"    .withColumn('unique_values', count_unique_udf(F.array(*df))).show(10)\\n\",\n",
    "        \")\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"GzvPnuqaTtzI\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"4948cc1e-846c-4dbf-b03a-a3f0b893eeaa\"\n",
    "      },\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\\n\",\n",
    "            \"|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|unique_values|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\\n\",\n",
    "            \"|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|            7|\\n\",\n",
    "            \"|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|            8|\\n\",\n",
    "            \"|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|            8|\\n\",\n",
    "            \"|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|            8|\\n\",\n",
    "            \"|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|            8|\\n\",\n",
    "            \"|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|            8|\\n\",\n",
    "            \"|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|            8|\\n\",\n",
    "            \"|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|            8|\\n\",\n",
    "            \"|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|            8|\\n\",\n",
    "            \"|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|            8|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\\n\",\n",
    "            \"only showing top 10 rows\\n\",\n",
    "            \"\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"# pandas_udf - тип SCALAR возвращает одно значение для каждой строки\\n\",\n",
    "        \"@pandas_udf(IntegerType(), PandasUDFType.SCALAR)\\n\",\n",
    "        \"def count_unique_pandas_udf(series) -> int:\\n\",\n",
    "        \"    return series.apply(lambda row: len(set(row)))\\n\",\n",
    "        \"(\\n\",\n",
    "        \"    df.filter(F.col('avg_price_before_sale').isNotNull())\\n\",\n",
    "        \"    .withColumn('unique_values', count_unique_pandas_udf(F.array(*df))).show(10)\\n\",\n",
    "        \")\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"P2sfqUzcZeJM\",\n",
    "        \"outputId\": \"bf447a19-ea70-4d80-8c17-9de1ebc16e54\"\n",
    "      },\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\\n\",\n",
    "            \"|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|unique_values|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\\n\",\n",
    "            \"|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|            7|\\n\",\n",
    "            \"|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|            8|\\n\",\n",
    "            \"|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|            8|\\n\",\n",
    "            \"|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|            8|\\n\",\n",
    "            \"|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|            8|\\n\",\n",
    "            \"|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|            8|\\n\",\n",
    "            \"|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|            8|\\n\",\n",
    "            \"|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|            8|\\n\",\n",
    "            \"|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|            8|\\n\",\n",
    "            \"|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|            8|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\\n\",\n",
    "            \"only showing top 10 rows\\n\",\n",
    "            \"\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"pmSZTI9PAwQb\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Задание 3\\n\",\n",
    "        \"SQL like case when или if elif else\\n\",\n",
    "        \"\\n\",\n",
    "        \"Создайте колонку, в которой в которой будет отображаться \\\"+\\\", \\\"-\\\" или \\\"=\\\", если \\\"Средняя стомость 10 проданных домов до текущего в том же районе\\\" больше, меньше или равно \\\"Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\\\", соотвественно.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Если одно из полей Null, запишите в эту колонку \\\"Нет данных\\\"\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"# сделаем задание через функцию when(если TRUE, тогда)\\n\",\n",
    "        \"df = df.withColumn(\\n\",\n",
    "        \"    'sign',\\n\",\n",
    "        \"    F.when(\\n\",\n",
    "        \"        F.col('avg_price_before_sale').isNull() | \\n\",\n",
    "        \"        F.col('avg_price_after_sale').isNull(),\\n\",\n",
    "        \"        'Нет данных'\\n\",\n",
    "        \"    ).when(\\n\",\n",
    "        \"        F.col('avg_price_before_sale') > F.col('avg_price_after_sale'),\\n\",\n",
    "        \"        '-'\\n\",\n",
    "        \"    ).when(\\n\",\n",
    "        \"        F.col('avg_price_before_sale') < F.col('avg_price_after_sale'),\\n\",\n",
    "        \"        '+'\\n\",\n",
    "        \"    ).otherwise(\\n\",\n",
    "        \"        '='\\n\",\n",
    "        \"    )\\n\",\n",
    "        \")\\n\",\n",
    "        \"# здесь уже не фильтруем null, чтоб посмотреть на \\\"Нет данных\\\" :)\\n\",\n",
    "        \"df.show()\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"0psn9uqHTulg\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"c33e4d0b-60cf-49db-9224-4c1c2364063e\"\n",
    "      },\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\\n\",\n",
    "            \"|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|      sign|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\\n\",\n",
    "            \"|2007-07-08 00:00:00|    2600| 327000|       house|       1|                 null|              708350|                  null|Нет данных|\\n\",\n",
    "            \"|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|         +|\\n\",\n",
    "            \"|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|         +|\\n\",\n",
    "            \"|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|         +|\\n\",\n",
    "            \"|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|         +|\\n\",\n",
    "            \"|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|         +|\\n\",\n",
    "            \"|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|         +|\\n\",\n",
    "            \"|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|         +|\\n\",\n",
    "            \"|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|         +|\\n\",\n",
    "            \"|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|         +|\\n\",\n",
    "            \"|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|         +|\\n\",\n",
    "            \"|2008-11-18 00:00:00|    2600| 950000|       house|       3|               679350|              701050|                635000|         +|\\n\",\n",
    "            \"|2008-11-21 00:00:00|    2600| 730000|       house|       3|               742850|              729550|                950000|         -|\\n\",\n",
    "            \"|2008-12-22 00:00:00|    2600| 855000|       house|       3|               786600|              716250|                730000|         -|\\n\",\n",
    "            \"|2008-12-24 00:00:00|    2600|1057500|       house|       4|               839200|              641500|                855000|         -|\\n\",\n",
    "            \"|2009-01-20 00:00:00|    2600|1150000|       house|       4|               715250|              641500|                475000|         -|\\n\",\n",
    "            \"|2009-01-22 00:00:00|    2600| 575000|       house|       3|               756250|              684000|               1150000|         -|\\n\",\n",
    "            \"|2009-02-13 00:00:00|    2600| 880000|       house|       4|               730550|              690700|                578000|         -|\\n\",\n",
    "            \"|2009-03-17 00:00:00|    2600|1015000|       house|       4|               701050|              735200|                410000|         +|\\n\",\n",
    "            \"|2009-03-28 00:00:00|    2600| 722000|       house|       4|               729550|              744000|               1015000|         +|\\n\",\n",
    "            \"+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\\n\",\n",
    "            \"only showing top 20 rows\\n\",\n",
    "            \"\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
